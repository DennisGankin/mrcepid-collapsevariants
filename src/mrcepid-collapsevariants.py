#!/usr/bin/env python
# mrcepid-collapsevariants 0.0.1
# Generated by dx-app-wizard.
#
# Author: Eugene Gardner (eugene.gardner at mrc.epid.cam.ac.uk)
#
# DNAnexus Python Bindings (dxpy) documentation:
#   http://autodoc.dnanexus.com/bindings/python/current/

import dxpy
import subprocess
import csv
import json
import tarfile
import glob


# This function runs a command on an instance, either with or without calling the docker instance we downloaded
# By default, commands are not run via Docker, but can be changed by setting is_docker = True
def run_cmd(cmd: str, is_docker: bool = False) -> None:

    if is_docker:
        # -v here mounts a local directory on an instance (in this case the home dir) to a directory internal to the
        # Docker instance named /test/. This allows us to run commands on files stored on the AWS instance within Docker
        cmd = "docker run " \
              "-v /home/dnanexus:/test " \
              "egardner413/mrcepid-filtering " + cmd

    # Standard python calling external commands protocol
    print(cmd)
    proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = proc.communicate()

    # If the command doesn't work, print the error stream and close the AWS instance out with 'dxpy.AppError'
    if proc.returncode != 0:
        print("The following cmd failed:")
        print(cmd)
        print("STDERROR follows\n")
        print(stderr.decode('utf-8'))
        raise dxpy.AppError("Failed to run properly...")


# Runs a filtering expression provided by the user to INCLUDE (-i) a subset of variants from the associated filtered VCF
# file.
# The expression MUST be in a format parseable by bcftools -i and must be formated to INCLUDE the desired variants –
# there is currently no option to use an exclusion format (-e)
def run_filtering(expression: str) -> None:

    # Simple bcftools view command that includes variants in the filtering expression and just outputs a new "filtered"
    # bcf file
    cmd = "bcftools view -i \'" + expression + "\' -Ob -o /test/variants.filtered.bcf /test/variants.vcf.gz"
    run_cmd(cmd, True)
    # Just to get the samples present in the file for later functions – not used here
    cmd = "bcftools query -l /test/variants.filtered.bcf > samples.txt"
    run_cmd(cmd, True)


# Generate input format files that can be provided to BOLT
def parse_filters_BOLT(vcfprefix: str, file_prefix: str) -> None:

    # Get all possible samples and place into a dictionary indexed by sample ID to store genotype-level information
    samples_file = open('samples.txt', 'r', newline='\n')
    samples = dict()
    for sample in samples_file:
        sample = sample.rstrip()
        samples[sample] = {'eid': sample}

    # Get out BCF file into a tab-delimited format that we can parse for BOLT.
    # We ONLY want alternate alleles here (-i 'GT="alt") and then for each row print:
    # 1. Sample ID: UKBB eid format
    # 2. The actual genotype (0/1 or 1/1 in this case)
    # 3. The ENSG ID so we know what gene this value is derived for
    cmd = "bcftools query -i \'GT=\"alt\"\'  -f \'[%SAMPLE\\t%GT\\t%ENSG\\n]\' -o /test/parsed.txt /test/variants.filtered.bcf"
    run_cmd(cmd, True)
    # This is just a list-format of the above file's header so we can read it in below with index-able columns
    header = ['sample', 'genotype', 'ENSG']

    # Now we are going to read this file in and parse the genotype information into the dictionary we created above (samples)
    filtered_variants = csv.DictReader(open('parsed.txt', 'r', newline= '\n'), fieldnames=header, delimiter="\t", quoting = csv.QUOTE_NONE)
    for var in filtered_variants:
        # IF the gene is already present for this individual, increment based on genotype
        # ELSE the gene is NOT already present for this individual, instantiate a new level in the samples dict and set
        # according to current genotype
        if var['ENSG'] in samples[var['sample']]:
            samples[var['sample']][var['ENSG']] += 1 if var['genotype'] == '0/1' else 2
        else:
            samples[var['sample']][var['ENSG']] = 1 if var['genotype'] == '0/1' else 2

    # Output this in json format for easy parsing by the next applet in this workflow (mrcepid-mergecollapsevariants)
    # This will allow for easy merging of .json files across multiple VCF files
    output = open(vcfprefix + "." + file_prefix + '.BOLT.json', 'w')
    json.dump(samples, output) # This just dumps the json/dict (samples) into the file provided by output
    output.close()


# Generate input format files that can be provided to REGENIE
# BIG NOTE: REGENIE is not yet implemented in this workflow, but the file format required for REGENIE is helpful for
# other tools that I need to run (e.g. SAIGE and GLM), so have retained
def parse_filters_REGENIE(vcfprefix: str, file_prefix: str) -> None:

    # Create a rare variant plink file. Important parameters explained:
    # --bcf                   : the filtered bcf file that we created above using run_filtering()
    # --set-all-var-ids       : The naming convention of variants in the BCF file is not compatible with downstream
    #                           software so we change it here
    # --new-id-max-allele-len : Due to InDels, the new var-ids can have names that are too long for standard plink
    #                           output. My hope is 100 characters is enough, but this could break at some point...
    cmd = "plink2 --bcf /test/variants.filtered.bcf --out /test/" + vcfprefix + "." + file_prefix + \
          ".REGENIE --make-pgen --set-all-var-ids @:#:\$r:\$a --new-id-max-allele-len 100"
    run_cmd(cmd, True)

    # Make annotation file:
    # REGENIE and other tools require a separate annotation file that states the GENE and estimated consequence. This
    # file is used later by mrcepid-mergecollapsevariants
    # Note the column in the bcftools query -f of %CHROM:%POS:%REF:%ALT – this is the same format as done for the above
    # plink2 command to keep things consistent for later
    cmd = "bcftools query -f '%CHROM\t%POS\t%CHROM:%POS:%REF:%ALT\t%ENSG\t%PARSED_CSQ\n' " \
          "-o /test/" + vcfprefix + "." + file_prefix + ".REGENIE.annotation.txt /test/variants.filtered.bcf"
    run_cmd(cmd, True)


# Generate input format files that can be provided to STAAR
def parse_filters_STAAR(vcfprefix: str, file_prefix: str) -> None:

    # STAAR requires me to make a "matrix" with rows of IDs and Columns of individual variants:
    # rows can be pulled from the pfam file generated by parse_filtered_REGENIE
    # columns can be pulled from the same file as REGENIE annotation
    # The actual "insides" (i.e. matrix[i][j]) print here. Here doing it in sparse matrix format where I just give the
    # sample ID (row) x var ID (col). So each row of the file generated by the below command is one cell in the
    # resulting matrix
    cmd = "bcftools query -i \'GT=\"alt\"\'  -f '[%SAMPLE\t%CHROM:%POS:%REF:%ALT\t%GT\n]' " \
          "-o /test/" + vcfprefix + "." + file_prefix + ".STAAR.matrix.txt /test/variants.filtered.bcf"
    run_cmd(cmd, True)


@dxpy.entry_point('main')
def main(input_vcf, filtering_expression, file_prefix):

    # For logging purposes output the filtering expression provided by the user
    print("Current Filtering Expression:")
    print(filtering_expression)

    # Bring our docker image into our environment so that we can run commands we need:
    cmd = "docker pull egardner413/mrcepid-filtering:latest"
    run_cmd(cmd)

    # Injest the filtered VCF file into this instance
    vcf = dxpy.DXFile(input_vcf)
    vcfprefix = vcf.describe()['name'].rstrip(".vcf.gz") # Get a prefix name for all files
    dxpy.download_dxfile(vcf.get_id(), "variants.vcf.gz")

    # Run filtering according to the user-provided filtering expression
    run_filtering(filtering_expression)

    # Here we are then taking the file generated by run_filtering() and generating various text/plink/vcf files
    # that will be used as part of mrcepid-mergecollapsevariants to generated a merged set of variants we want to
    # test across all VCF files
    # JUST TO BE CLEAR – the names of the functions here are not THAT important. e.g. files generated in the function
    # parse_filters_REGENIE() will be used for other tools. It was just for me (Eugene Gardner) to keep things
    # organised when writing this function
    parse_filters_BOLT(vcfprefix, file_prefix) # BOLT
    parse_filters_REGENIE(vcfprefix, file_prefix) # REGENIE
    parse_filters_STAAR(vcfprefix, file_prefix) # STAAR

    # Here we are taking all of the files generated by the various functions above and adding them to a single tar
    # to enable easy output. The only output of this applet is thus a single .tar.gz file per VCF file
    output_tarball = vcfprefix + "." + file_prefix + ".tar.gz"
    tar = tarfile.open(output_tarball, "w:gz")
    for file in glob.glob(vcfprefix + "." + file_prefix + ".*"):
        tar.add(file)
    output_tarball.close()

    # Set output
    output = {'output_tarball': dxpy.dxlink(dxpy.upload_local_file(output_tarball))}

    return output

dxpy.run()
